{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "td = \"/Users/sreenathgv/Learning/Masters/Social_Dynamics_Lab/Reddit_populism/td_data_v2.csv\"\n",
    "sfp = \"/Users/sreenathgv/Learning/Masters/Social_Dynamics_Lab/Reddit_populism/sfp_data_v2.csv\"\n",
    "neither = \"/Users/sreenathgv/Learning/Masters/Social_Dynamics_Lab/Reddit_populism/neither_sample.csv\"\n",
    "coding = \"/Users/sreenathgv/Learning/Masters/Social_Dynamics_Lab/Reddit_populism/political_coding_fix.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The_Donald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_coding = pd.read_csv(coding)\n",
    "with open(td) as f:\n",
    "    reader = csv.reader(f) \n",
    "    first_row = True  \n",
    "    \n",
    "    # author_history_td : dict {'author':[(subreddit, timestamp), ...................,(subreddit, timestamp)}\n",
    "    author_history_td = {}\n",
    "    for row in reader:\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue   \n",
    "        author = row[0]\n",
    "        subreddit = row[1]\n",
    "        created_utc = row[3]\n",
    "        \n",
    "        if author in author_history_td.keys():\n",
    "            author_history_td[author].append((subreddit, int(created_utc)))\n",
    "        else:\n",
    "            author_history_td[author] = [(subreddit, int(created_utc))]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the cutoff dates for each author and subset the data set accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dt_range = defaultdict()\n",
    "author_hist_td_subset = defaultdict()\n",
    "unique_subreddits = set()\n",
    "\n",
    "# For each author finding the UTC cutoff: [first post in r/The_Donald]\n",
    "for auth in author_history_td:\n",
    "    td_lst = []\n",
    "    for item in author_history_td[auth]:\n",
    "        if item[0] == 'The_Donald':\n",
    "            td_lst.append(item)\n",
    "        else:\n",
    "            unique_subreddits.add(item[0])\n",
    "            \n",
    "    end_dt = min(td_lst, key=operator.itemgetter(1))[1]\n",
    "    author_dt_range[auth] = end_dt\n",
    "\n",
    "# Subset the data to include only posts before UTC\n",
    "for auth in author_history_td:\n",
    "    author_hist_td_subset[auth] = [x for x in author_history_td[auth] if (x[1] < author_dt_range[auth])]\n",
    "\n",
    "unique_authors_td = list(author_dt_range.keys())\n",
    "author_idx = defaultdict()\n",
    "subreddit_idx = defaultdict()\n",
    "author_idx = {k: v for v, k in enumerate(list(author_dt_range.keys()))}\n",
    "subreddit_idx = {k: v for v, k in enumerate(list(unique_subreddits))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the data subset above, for each author we compute the count of posts in each subreddit(tp_part_matrix). \n",
    "2. To find participation proportion we divide the counts by total number of posts made by the author. Both count as well participation scores are represented as numpy arrays.\n",
    "3. Final participation proportion for a subreddit, is the average proportion across all authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_part_matrix = np.zeros((len(author_idx),len(subreddit_idx)))\n",
    "for auth in author_hist_td_subset:\n",
    "    aut_idx = author_idx[auth]\n",
    "    for item in author_hist_td_subset[auth]:\n",
    "        sub_idx = subreddit_idx[item[0]]\n",
    "        td_part_matrix[aut_idx][sub_idx] += 1\n",
    "\n",
    "td_part_prop = np.copy(td_part_matrix)\n",
    "td_part_prop = (td_part_prop.T/(np.sum(td_part_prop, axis =1))).T\n",
    "td_sub_participation = np.mean(td_part_prop, axis =0)\n",
    "\n",
    "subs = []\n",
    "for i, item in enumerate(subreddit_idx.keys()):\n",
    "    subs.append((item,round(td_sub_participation[subreddit_idx[item]]*100,2)))\n",
    "td_sorted_subs = sorted(subs,key=operator.itemgetter(1),reverse = True)\n",
    "td_participation = pd.DataFrame(td_sorted_subs, columns=['subreddit', 'participation_prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>participation_prop</th>\n",
       "      <th>political</th>\n",
       "      <th>populist</th>\n",
       "      <th>partisan_lean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>7.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>4.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>3.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pics</td>\n",
       "      <td>2.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>2.61</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>2.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>videos</td>\n",
       "      <td>1.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nfl</td>\n",
       "      <td>1.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WTF</td>\n",
       "      <td>1.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gaming</td>\n",
       "      <td>1.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nba</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>atheism</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trees</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IAmA</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>technology</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit  participation_prop political populist partisan_lean\n",
       "0             AskReddit                7.52       NaN      NaN           NaN\n",
       "1              politics                4.65       Yes       No          Left\n",
       "2                 funny                3.05       NaN      NaN           NaN\n",
       "3                  pics                2.71       NaN      NaN           NaN\n",
       "4   SandersForPresident                2.61       Yes      Yes          Left\n",
       "5         AdviceAnimals                2.37       NaN      NaN           NaN\n",
       "6             worldnews                2.00       NaN      NaN           NaN\n",
       "7       leagueoflegends                1.94       NaN      NaN           NaN\n",
       "8                videos                1.74       NaN      NaN           NaN\n",
       "9                  news                1.72       NaN      NaN           NaN\n",
       "10        todayilearned                1.70       NaN      NaN           NaN\n",
       "11                  nfl                1.55       NaN      NaN           NaN\n",
       "12                  WTF                1.51       NaN      NaN           NaN\n",
       "13               gaming                1.37       NaN      NaN           NaN\n",
       "14                  nba                0.96       NaN      NaN           NaN\n",
       "15              atheism                0.91       NaN      NaN           NaN\n",
       "16               movies                0.87       NaN      NaN           NaN\n",
       "17                trees                0.81       NaN      NaN           NaN\n",
       "18                 IAmA                0.80       NaN      NaN           NaN\n",
       "19           technology                0.73       NaN      NaN           NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_participation_ful = pd.merge(td_participation, political_coding, on='subreddit', how='left')\n",
    "td_participation_ful.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_participation_ful.to_csv(\"The_Donald_participation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sfp) as f:\n",
    "    reader = csv.reader(f) \n",
    "    first_row = True  \n",
    "    \n",
    "    # author_history_sfp : dict {'author':[(subreddit, timestamp), ...................,(subreddit, timestamp)}\n",
    "    author_history_sfp = {}\n",
    "    for row in reader:\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue   \n",
    "        author = row[0]\n",
    "        subreddit = row[1]\n",
    "        created_utc = row[3]\n",
    "        \n",
    "        if author in author_history_sfp.keys():\n",
    "            author_history_sfp[author].append((subreddit, int(created_utc)))\n",
    "        else:\n",
    "            author_history_sfp[author] = [(subreddit, int(created_utc))]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dt_range = defaultdict()\n",
    "author_hist_sfp_subset = defaultdict()\n",
    "unique_subreddits = set()\n",
    "\n",
    "# For each author finding the UTC cutoff: [first post in r/The_Donald]\n",
    "for auth in author_history_sfp:\n",
    "    sfp_lst = []\n",
    "    for item in author_history_sfp[auth]:\n",
    "        if item[0] == 'SandersForPresident':\n",
    "            sfp_lst.append(item)\n",
    "        else:\n",
    "            unique_subreddits.add(item[0])\n",
    "            \n",
    "    end_dt = min(sfp_lst, key=operator.itemgetter(1))[1]\n",
    "    author_dt_range[auth] = end_dt\n",
    "\n",
    "# Subset the data to include only posts before UTC\n",
    "for auth in author_history_sfp:\n",
    "    author_hist_sfp_subset[auth] = [x for x in author_history_sfp[auth] if (x[1] < author_dt_range[auth])]\n",
    "\n",
    "unique_authors_sfp = list(author_dt_range.keys())\n",
    "author_idx = defaultdict()\n",
    "subreddit_idx = defaultdict()\n",
    "author_idx = {k: v for v, k in enumerate(list(author_dt_range.keys()))}\n",
    "subreddit_idx = {k: v for v, k in enumerate(list(unique_subreddits))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_part_matrix = np.zeros((len(author_idx),len(subreddit_idx)))\n",
    "\n",
    "for auth in author_hist_sfp_subset:\n",
    "    aut_idx = author_idx[auth]\n",
    "    for item in author_hist_sfp_subset[auth]:\n",
    "        sub_idx = subreddit_idx[item[0]]\n",
    "        sfp_part_matrix[aut_idx][sub_idx] += 1\n",
    "\n",
    "\n",
    "sfp_part_prop = np.copy(sfp_part_matrix)\n",
    "sfp_part_prop = (sfp_part_prop.T/(np.sum(sfp_part_prop, axis =1))).T\n",
    "sfp_sub_participation = np.mean(sfp_part_prop, axis =0)\n",
    "\n",
    "\n",
    "subs = []\n",
    "for i, item in enumerate(subreddit_idx.keys()):\n",
    "    subs.append((item,round(sfp_sub_participation[subreddit_idx[item]]*100,2)))\n",
    "sfp_sorted_subs = sorted(subs,key=operator.itemgetter(1),reverse = True)\n",
    "\n",
    "sfp_participation = pd.DataFrame(sfp_sorted_subs, columns=['subreddit', 'participation_prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>participation_prop</th>\n",
       "      <th>political</th>\n",
       "      <th>populist</th>\n",
       "      <th>partisan_lean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>9.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funny</td>\n",
       "      <td>2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pics</td>\n",
       "      <td>2.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>2.27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>videos</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WTF</td>\n",
       "      <td>1.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gaming</td>\n",
       "      <td>1.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nfl</td>\n",
       "      <td>1.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>news</td>\n",
       "      <td>1.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>atheism</td>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nba</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IAmA</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trees</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CFB</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  participation_prop political populist partisan_lean\n",
       "0         AskReddit                9.27       NaN      NaN           NaN\n",
       "1             funny                2.78       NaN      NaN           NaN\n",
       "2              pics                2.53       NaN      NaN           NaN\n",
       "3          politics                2.27       Yes       No          Left\n",
       "4     AdviceAnimals                1.88       NaN      NaN           NaN\n",
       "5   leagueoflegends                1.52       NaN      NaN           NaN\n",
       "6            videos                1.50       NaN      NaN           NaN\n",
       "7         worldnews                1.50       NaN      NaN           NaN\n",
       "8               WTF                1.40       NaN      NaN           NaN\n",
       "9            gaming                1.35       NaN      NaN           NaN\n",
       "10    todayilearned                1.24       NaN      NaN           NaN\n",
       "11              nfl                1.19       NaN      NaN           NaN\n",
       "12             news                1.19       NaN      NaN           NaN\n",
       "13          atheism                1.04       NaN      NaN           NaN\n",
       "14              nba                1.00       NaN      NaN           NaN\n",
       "15             IAmA                0.84       NaN      NaN           NaN\n",
       "16           movies                0.83       NaN      NaN           NaN\n",
       "17            trees                0.83       NaN      NaN           NaN\n",
       "18              CFB                0.72       NaN      NaN           NaN\n",
       "19     pcmasterrace                0.61       NaN      NaN           NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfp_participation_ful = pd.merge(sfp_participation, political_coding, on='subreddit', how='left')\n",
    "sfp_participation_ful.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_participation_ful.to_csv(\"Sanders_for_President_participation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_coding = pd.read_csv(coding)\n",
    "with open(neither) as f:\n",
    "    reader = csv.reader(f) \n",
    "    first_row = True  \n",
    "    \n",
    "    # author_history_nt : dict {'author':[(subreddit, timestamp), ...................,(subreddit, timestamp)}\n",
    "    author_history_nt = {}\n",
    "    for row in reader:\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue   \n",
    "        author = row[0]\n",
    "        subreddit = row[1]\n",
    "        created_utc = row[3]\n",
    "        \n",
    "        if author in author_history_nt.keys():\n",
    "            author_history_nt[author].append((subreddit, int(created_utc)))\n",
    "        else:\n",
    "            author_history_nt[author] = [(subreddit, int(created_utc))]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_hist_nt_subset = defaultdict()\n",
    "unique_subreddits = set()\n",
    "unique_authors_nt = set()\n",
    "\n",
    "for auth in author_history_nt:\n",
    "    unique_authors_nt.add(auth)\n",
    "    for item in author_history_nt[auth]:\n",
    "        unique_subreddits.add(item[0])\n",
    "\n",
    "unique_authors_nt = list(unique_authors_nt)\n",
    "# Subset the data to include only posts before UTC\n",
    "for auth in author_history_nt:\n",
    "    author_hist_nt_subset[auth] = [x for x in author_history_nt[auth] if (x[1] < 1514764799)]\n",
    "\n",
    "author_idx = defaultdict()\n",
    "subreddit_idx = defaultdict()\n",
    "author_idx = {k: v for v, k in enumerate(list(unique_authors_nt))}\n",
    "subreddit_idx = {k: v for v, k in enumerate(list(unique_subreddits))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_part_matrix = np.zeros((len(author_idx),len(subreddit_idx)))\n",
    "for auth in author_hist_nt_subset:\n",
    "    aut_idx = author_idx[auth]\n",
    "    for item in author_hist_nt_subset[auth]:\n",
    "        sub_idx = subreddit_idx[item[0]]\n",
    "        nt_part_matrix[aut_idx][sub_idx] += 1\n",
    "\n",
    "nt_part_prop = np.copy(nt_part_matrix)\n",
    "nt_part_prop = (nt_part_prop.T/(np.sum(nt_part_prop, axis =1))).T\n",
    "nt_sub_participation = np.mean(nt_part_prop, axis =0)\n",
    "\n",
    "subs = []\n",
    "for i, item in enumerate(subreddit_idx.keys()):\n",
    "    subs.append((item,round(nt_sub_participation[subreddit_idx[item]]*100,2)))\n",
    "nt_sorted_subs = sorted(subs,key=operator.itemgetter(1),reverse = True)\n",
    "nt_participation = pd.DataFrame(nt_sorted_subs, columns=['subreddit', 'participation_prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>participation_prop</th>\n",
       "      <th>political</th>\n",
       "      <th>populist</th>\n",
       "      <th>partisan_lean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>8.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funny</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pics</td>\n",
       "      <td>1.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaming</td>\n",
       "      <td>1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WTF</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>1.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>videos</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>politics</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IAmA</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nfl</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nba</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>soccer</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trees</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gonewild</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atheism</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  participation_prop political populist partisan_lean\n",
       "0         AskReddit                8.79       NaN      NaN           NaN\n",
       "1             funny                2.18       NaN      NaN           NaN\n",
       "2              pics                1.98       NaN      NaN           NaN\n",
       "3   leagueoflegends                1.93       NaN      NaN           NaN\n",
       "4            gaming                1.33       NaN      NaN           NaN\n",
       "5               WTF                1.25       NaN      NaN           NaN\n",
       "6     AdviceAnimals                1.15       NaN      NaN           NaN\n",
       "7            videos                1.11       NaN      NaN           NaN\n",
       "8          politics                1.01       Yes       No          Left\n",
       "9     todayilearned                0.98       NaN      NaN           NaN\n",
       "10             IAmA                0.94       NaN      NaN           NaN\n",
       "11              nfl                0.89       NaN      NaN           NaN\n",
       "12        worldnews                0.87       NaN      NaN           NaN\n",
       "13              nba                0.76       NaN      NaN           NaN\n",
       "14           soccer                0.73       NaN      NaN           NaN\n",
       "15            trees                0.65       NaN      NaN           NaN\n",
       "16           movies                0.57       NaN      NaN           NaN\n",
       "17            DotA2                0.57       NaN      NaN           NaN\n",
       "18         gonewild                0.56       NaN      NaN           NaN\n",
       "19          atheism                0.55       NaN      NaN           NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_participation_ful = pd.merge(nt_participation, political_coding, on='subreddit', how='left')\n",
    "nt_participation_ful.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_TD_SFP = list(set(unique_authors_sfp) & set(unique_authors_td))\n",
    "perc_TD_in_SFP = len(overlap_TD_SFP)*100/len(unique_authors_td)\n",
    "perc_TD_in_SFP\n",
    "\n",
    "perc_SFP_in_TD = len(overlap_TD_SFP)*100/len(unique_authors_sfp)\n",
    "perc_SFP_in_TD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policital, Populist, Partisan Lean Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  \n",
      "The_Donald: Average paricipation proportion  \u001b[0m\n",
      "\n",
      " Political:\n",
      "  political  participation_prop\n",
      "0       Yes            0.009474\n",
      "\n",
      " Populist:\n",
      "  populist  participation_prop\n",
      "0       No            0.022979\n",
      "1  Unknown            0.000667\n",
      "2      Yes            0.005500\n",
      "\n",
      " partisan_lean:\n",
      "  partisan_lean  participation_prop\n",
      "0      Centrist            0.000000\n",
      "1          Left            0.015217\n",
      "2         Right            0.007551\n",
      "3       Unknown            0.000714\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m  \\nThe_Donald: Average paricipation proportion  \\033[0m')\n",
    "\n",
    "print(\"\\n Political:\")\n",
    "print(td_participation_ful.groupby('political', as_index=False)['participation_prop'].mean())\n",
    "\n",
    "print(\"\\n Populist:\")\n",
    "print(td_participation_ful.groupby('populist', as_index=False)['participation_prop'].mean())\n",
    "\n",
    "print(\"\\n partisan_lean:\")\n",
    "print(td_participation_ful.groupby('partisan_lean', as_index=False)['participation_prop'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  \n",
      " Sanders_For_President : Average paricipation proportion  \u001b[0m\n",
      "\n",
      " Political:\n",
      "  political  participation_prop\n",
      "0       Yes            0.012833\n",
      "\n",
      " Populist:\n",
      "  populist  participation_prop\n",
      "0       No            0.044464\n",
      "1  Unknown            0.002090\n",
      "2      Yes            0.006647\n",
      "\n",
      " partisan_lean:\n",
      "  partisan_lean  participation_prop\n",
      "0      Centrist            0.000000\n",
      "1          Left            0.015872\n",
      "2         Right            0.012933\n",
      "3       Unknown            0.001463\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m  \\n Sanders_For_President : Average paricipation proportion  \\033[0m')\n",
    "\n",
    "print(\"\\n Political:\")\n",
    "print(sfp_participation_ful.groupby('political', as_index=False)['participation_prop'].mean())\n",
    "\n",
    "print(\"\\n Populist:\")\n",
    "print(sfp_participation_ful.groupby('populist', as_index=False)['participation_prop'].mean())\n",
    "\n",
    "print(\"\\n partisan_lean:\")\n",
    "print(sfp_participation_ful.groupby('partisan_lean', as_index=False)['participation_prop'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
