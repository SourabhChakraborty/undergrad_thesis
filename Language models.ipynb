{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import nltk\n",
    "import kenlm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_data = pd.read_csv(\"../sample_data/sfp_data_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_data = pd.read_csv(\"../sample_data/td_data_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_authors = sfp_data['author'].unique()\n",
    "td_authors = td_data['author'].unique()\n",
    "\n",
    "sfp_posts = sfp_data.loc[sfp_data['subreddit'] == 'SandersForPresident']\n",
    "td_posts = td_data.loc[td_data['subreddit'] == 'The_Donald']\n",
    "\n",
    "sfp_min_times = [min(sfp_posts.loc[sfp_posts['author'] == auth]['created_utc']) for auth in sfp_authors]\n",
    "td_min_times = [min(td_posts.loc[td_posts['author'] == auth]['created_utc']) for auth in td_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4868749, 5)\n",
      "(4003940, 5)\n",
      "2000\n",
      "2000\n",
      "(78037, 5)\n",
      "(55521, 5)\n"
     ]
    }
   ],
   "source": [
    "print(sfp_data.shape)\n",
    "print(td_data.shape)\n",
    "print(len(sfp_authors))\n",
    "print(len(td_authors))\n",
    "print(sfp_posts.shape)\n",
    "print(td_posts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233708, 5)\n",
      "(89894, 5)\n"
     ]
    }
   ],
   "source": [
    "sfp_politics = sfp_data.loc[sfp_data['subreddit'] == 'politics']\n",
    "td_politics = td_data.loc[td_data['subreddit'] == 'politics']\n",
    "print(sfp_politics.shape)\n",
    "print(td_politics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_politics_before = pd.DataFrame([], columns = sfp_politics.columns)\n",
    "sfp_politics_after = pd.DataFrame([], columns = sfp_politics.columns)\n",
    "\n",
    "for i in range(len(sfp_authors)):\n",
    "    curr_auth_posts = sfp_politics.loc[sfp_politics['author'] == sfp_authors[i]]\n",
    "    \n",
    "    if len(curr_auth_posts) > 0:\n",
    "        sfp_politics_before = \\\n",
    "sfp_politics_before.append(curr_auth_posts.loc[curr_auth_posts['created_utc'] < sfp_min_times[i]])\n",
    "        \n",
    "        sfp_politics_after = \\\n",
    "sfp_politics_after.append(curr_auth_posts.loc[curr_auth_posts['created_utc'] > sfp_min_times[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_politics_before = pd.DataFrame([], columns = td_politics.columns)\n",
    "td_politics_after = pd.DataFrame([], columns = td_politics.columns)\n",
    "\n",
    "for i in range(len(td_authors)):\n",
    "    curr_auth_posts = td_politics.loc[td_politics['author'] == td_authors[i]]\n",
    "    \n",
    "    if len(curr_auth_posts) > 0:\n",
    "        td_politics_before = \\\n",
    "td_politics_before.append(curr_auth_posts.loc[curr_auth_posts['created_utc'] < td_min_times[i]])\n",
    "        \n",
    "        td_politics_after = \\\n",
    "td_politics_after.append(curr_auth_posts.loc[curr_auth_posts['created_utc'] > td_min_times[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_politics_before_text = sfp_politics_before.loc[sfp_politics_before['body'].notna()]['body'].values\n",
    "sfp_politics_after_text = sfp_politics_after.loc[sfp_politics_after['body'].notna()]['body'].values\n",
    "\n",
    "td_politics_before_text = td_politics_before.loc[td_politics_before['body'].notna()]['body'].values\n",
    "td_politics_after_text = td_politics_after.loc[td_politics_after['body'].notna()]['body'].values\n",
    "\n",
    "sfp_posts_text = sfp_posts.loc[sfp_posts['body'].notna()]['body'].values\n",
    "td_posts_text = td_posts.loc[td_posts['body'].notna()]['body'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_arrs = [sfp_politics_before_text,\n",
    "             sfp_politics_after_text,\n",
    "             td_politics_before_text,\n",
    "             td_politics_after_text,\n",
    "             sfp_posts_text,\n",
    "             td_posts_text]\n",
    "\n",
    "test_arrs = []\n",
    "\n",
    "for i in range(len(text_arrs)):\n",
    "    lm_test_arr = \\\n",
    "[(' '.join(nltk.word_tokenize(s)).lower()) for v in text_arrs[i] for s in nltk.sent_tokenize(v)]\n",
    "    test_arrs.append(lm_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367959\n",
      "[\"presidential run aside , i do n't understand why you make the assumption that he 's nothing without his comedy writers .\", 'he is one of his own comedy writers .', 'aside from being the host of the show , colbert is an executive producer and has written about as many episodes as any other writer .', '[ imdb source ] ( http : //www.imdb.com/title/tt0458254/fullcredits )', \"that 's because those numbers include [ superdelegates ] ( http : //en.wikipedia.org/wiki/superdelegate ) , which are not won via the caucus .\", 'obama won more pledged delegates in iowa , which are assigned based on the iowan caucus .', \"but questionmark 's original comment stated that hillary won more delegates in iowa , which is not true .\", \"she won fewer pledged delegates than obama , and even when you include superdelegates , she 's not ahead in iowa .\", 'i mentioned that in my [ previous comment ] ( http : //politics.reddit.com/info/65zyd/comments/c02xwsj ) .', 'the numbers you posted represent the national results on 01/04/08 .']\n",
      "\n",
      "\n",
      "\n",
      "353333\n",
      "[\"there 's a lot involved including exit polls and demographics/precinct math .\", 'halfway down this page is the table that matters .', 'the candidates need to hit these delegate marks to be on pace for the nomination : http : //projects.fivethirtyeight.com/election-2016/delegate-targets/democrats/', \"edited to say `` the candidates '' .\", 'i posted hastily .', 'i do not believe those are exit polls from today .', 'they may be for early voting in that state .', 'also that content appears to be down now , maybe the made a mistake .', 'edit : yup , these are placeholder numbers .', \"it 's way too early for exit numbers .\"]\n",
      "\n",
      "\n",
      "\n",
      "216725\n",
      "[\"& gt ; a sex scene comes on tv and its `` johnny cover your eyes ! ''\", 'are you sure ?', \"it 's more like `` jonny , do you know what they are doing ?\", \"[ ... sexual education comes here ... ] '' around here .\", \"really it 's more stupid by the american public to fall for that .\", 'in other countries politicians have done similarly stupid things , but mainly in america are politicians judged so much on their charisma .', \"that 's not how data analysis works .\", 'the way it works is a scientist writes a computer program which analyses it all in one go .', 'you need a couple of geniuses , not 10000 monkeys ; - )', 'that could certainly be the case , but i would not call that crowd sourcing..']\n",
      "\n",
      "\n",
      "\n",
      "60428\n",
      "[\"fuck i guess i 'm still in the running for the dnc candidate then too .\", 'innocent until proven guilty ?', 'what would stop hrc , or her camp , or any random joe for that matter , from making unfounded allegations against bernie sanders , or any political opponent , that would prompt an fbi investigation immediately making them ineligible for the nomination ?', 'i never said that .', \"i 'm saying you do n't make somebody ineligible for the dnc nomination based on allegations .\", 'you are trying to put words in my mouth and are being disingenuous and you know it .', \"i 'm saying you do n't make somebody ineligible for the dnc nomination based on allegations .\", 'you are trying to put words in my mouth and are being disingenuous and you know it .', 'believe it or not , it is a thing in a working democracy .', 'you are coocooo for coco puffs .']\n",
      "\n",
      "\n",
      "\n",
      "204878\n",
      "['i believe warren is more likely to see the war machine as an acceptable necessity , due to her stance on fighting terror and backing israel .', \"i 'd prefer to see a sanders/grayson run myself .\", 'alan grayson .', \"he 's genuinely progressive and outspoken , yet he 's managed to find ways to get libertarians and republicans to work with him on common ground issues .\", \"i could see him being able to publicly say the things a president probably should n't , and still be able to sway many conservatives to back sanders on constitutional and privacy issues .\", 'bill deblasio', 'actually frank jackson , mayor of cleveland might help .', \"as an old white guy i 'm not sure that sanders would have that much appeal to african americans .\", 'frank jackson is black , locally popular , and from a swing state .', \"as someone who worked on sherrod brown 's campaign i can tell you that i love his record and think he has the washington experience that is necessary for the job but he is not very inspirational .\"]\n",
      "\n",
      "\n",
      "\n",
      "115589\n",
      "['keeping it classy ...', 'look at that picture .', 'no shortage of minorities .', 'i think bernie sanders should be taking some cues from trump .', 'sanders attracts fairly lilly white crowds .', \"probably because he 's pro-illegal immigration .\", \"i ca n't think of a better explanation .\", \"he 's currently polling at twice the next best candidate in iowa .\", \"if the mccain thing did n't sink trump what do you think it 'll take ?\", \"let 's see how february works out for him .\"]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_arrs)):\n",
    "    print(len(test_arrs[i]))\n",
    "    print(test_arrs[i][:10])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367959\n",
      "353333\n",
      "216725\n",
      "60428\n",
      "204878\n",
      "115589\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_arrs)):\n",
    "    print(len(test_arrs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['politics_train.arpa',\n",
    "             'sfp_politics_before.arpa', \n",
    "             'sfp_politics_after.arpa',\n",
    "             'td_politics_before.arpa',\n",
    "             'td_politics_after.arpa',\n",
    "             'sfp_posts.arpa',\n",
    "             'td_posts.arpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram model\n",
      "2-gram model\n",
      "2-gram model\n",
      "2-gram model\n",
      "2-gram model\n",
      "2-gram model\n",
      "2-gram model\n"
     ]
    }
   ],
   "source": [
    "language_models = []\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    curr_lm = os.path.join(os.path.dirname('Language models.ipynb'), '..', 'language_models', filenames[i])\n",
    "    curr_model = kenlm.LanguageModel(curr_lm)\n",
    "    print('{0}-gram model'.format(curr_model.order))\n",
    "    language_models.append(curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', 'd'], dtype='<U1')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(['a','b','c','d'], 4, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(text1, text2, scoring_func, num_iters = 1000, sample_size = 1000):\n",
    "    lower_size = min(len(text1), len(text2))\n",
    "    text1_new = np.random.choice(text1, lower_size, replace=False)\n",
    "    text2_new = np.random.choice(text2, lower_size, replace=False)\n",
    "    \n",
    "    scores_all = [scoring_func(s) for s in (text1 + text2)]\n",
    "    bootstrap1 = []\n",
    "    bootstrap2 = []\n",
    "    random.seed(10)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        scores1 = random.sample(scores_all, sample_size)\n",
    "        scores2 = random.sample(scores_all, sample_size)\n",
    "        \n",
    "        bootstrap1.append(sum(scores1)/sample_size)\n",
    "        bootstrap2.append(sum(scores2)/sample_size)\n",
    "        \n",
    "    return (bootstrap1, bootstrap2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_values(text1, text2, scoring_func, num_iters = 1000, sample_size = 1000):\n",
    "    random.seed(10)\n",
    "    text1_sample = random.sample(text1, sample_size)\n",
    "    text2_sample = random.sample(text2, sample_size)\n",
    "    scores1 = [scoring_func(s) for s in text1_sample]\n",
    "    scores2 = [scoring_func(s) for s in text2_sample]\n",
    "\n",
    "    mean1 = sum(scores1)/len(scores1)\n",
    "    mean2 = sum(scores2)/len(scores2)\n",
    "    print(mean1)\n",
    "    print(mean2)\n",
    "    print()\n",
    "    \n",
    "    bootstrap1, bootstrap2 = bootstrap(text1, text2, scoring_func, num_iters)\n",
    "    model_diff = mean1 - mean2\n",
    "    print(model_diff)\n",
    "    print()\n",
    "    \n",
    "    bootstrap_diffs = [bootstrap1[i] - bootstrap2[i] for i in range(len(bootstrap1))]\n",
    "    print(sum([i > model_diff for i in bootstrap_diffs])/len(bootstrap_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466.0915190667158\n",
      "464.0644101356655\n",
      "\n",
      "2.027108931050293\n",
      "\n",
      "0.512\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, td_politics_before, sfp_politics_before\n",
    "calculate_values(test_arrs[0], test_arrs[2], language_models[1].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415.26142824930616\n",
      "390.3400073401792\n",
      "\n",
      "24.921420909126937\n",
      "\n",
      "0.438\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, td_politics_before, td_politics_before\n",
    "calculate_values(test_arrs[0], test_arrs[2], language_models[3].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.7865394483283\n",
      "516.1244845746966\n",
      "\n",
      "-167.33794512636825\n",
      "\n",
      "0.877\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_after, td_politics_after, sfp_politics_after\n",
    "calculate_values(test_arrs[1], test_arrs[3], language_models[2].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.5069705611644\n",
      "414.18445782481314\n",
      "\n",
      "-61.67748726364874\n",
      "\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_after, td_politics_after, td_politics_after\n",
    "calculate_values(test_arrs[1], test_arrs[3], language_models[4].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452.27702955300754\n",
      "442.24635122921\n",
      "\n",
      "10.030678323797531\n",
      "\n",
      "0.478\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, td_politics_before, sfp_posts\n",
    "calculate_values(test_arrs[0], test_arrs[2], language_models[5].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411.0995839632289\n",
      "390.2742375488254\n",
      "\n",
      "20.825346414403498\n",
      "\n",
      "0.376\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, td_politics_before, td_posts\n",
    "calculate_values(test_arrs[0], test_arrs[2], language_models[6].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.5910337341523\n",
      "526.1723508792212\n",
      "\n",
      "-164.5813171450689\n",
      "\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_after, td_politics_after, sfp_posts\n",
    "calculate_values(test_arrs[1], test_arrs[3], language_models[5].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357.7513617089054\n",
      "376.5504233294564\n",
      "\n",
      "-18.799061620551015\n",
      "\n",
      "0.607\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_after, td_politics_after, td_posts\n",
    "calculate_values(test_arrs[1], test_arrs[3], language_models[6].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386.99331096744527\n",
      "395.1014610810287\n",
      "\n",
      "-8.108150113583406\n",
      "\n",
      "0.531\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, td_politics_before, politics\n",
    "calculate_values(test_arrs[0], test_arrs[2], language_models[0].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349.8563032214515\n",
      "439.71758078008185\n",
      "\n",
      "-89.86127755863032\n",
      "\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_after, td_politics_after, politics\n",
    "calculate_values(test_arrs[1], test_arrs[3], language_models[0].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372.3425881771748\n",
      "1437.7450103397887\n",
      "\n",
      "-1065.402422162614\n",
      "\n",
      "0.998\n"
     ]
    }
   ],
   "source": [
    "# sfp_posts, td_posts, sfp_posts\n",
    "calculate_values(test_arrs[4], test_arrs[5], language_models[5].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383.91765532531605\n",
      "658.0044753733365\n",
      "\n",
      "-274.08682004802046\n",
      "\n",
      "0.963\n"
     ]
    }
   ],
   "source": [
    "# sfp_posts, td_posts, td_posts\n",
    "calculate_values(test_arrs[4], test_arrs[5], language_models[6].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654.1731912362627\n",
      "437.5470999445293\n",
      "\n",
      "216.62609129173342\n",
      "\n",
      "0.069\n"
     ]
    }
   ],
   "source": [
    "# td_posts, sfp_posts, td_posts\n",
    "calculate_values(test_arrs[5], test_arrs[4], language_models[6].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393.96497182012\n",
      "987.3871161287846\n",
      "\n",
      "-593.4221443086645\n",
      "\n",
      "0.999\n"
     ]
    }
   ],
   "source": [
    "# sfp_posts, td_posts, politics\n",
    "calculate_values(test_arrs[4], test_arrs[5], language_models[0].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386.99331096744527\n",
      "357.0470253137992\n",
      "\n",
      "29.946285653646044\n",
      "\n",
      "0.321\n"
     ]
    }
   ],
   "source": [
    "# sfp_politics_before, sfp_politics_after, politics\n",
    "calculate_values(test_arrs[0], test_arrs[1], language_models[0].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380.8497134050213\n",
      "452.1804452783587\n",
      "\n",
      "-71.33073187333741\n",
      "\n",
      "0.849\n"
     ]
    }
   ],
   "source": [
    "# td_politics_before, td_politics_after, politics\n",
    "calculate_values(test_arrs[2], test_arrs[3], language_models[0].perplexity, num_iters=1000, sample_size = 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
